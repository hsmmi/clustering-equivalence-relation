{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from my_io import read_dataset_to_X_and_y, print_array_with_dataframe\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole dataset is (615, 12) matrix\n"
     ]
    }
   ],
   "source": [
    "class UniSet():\n",
    "    def __init__(self, file, range_feature, range_label,\n",
    "                 normalization=None, shuffle=False, about_nan='class_mean'):\n",
    "        np.random.seed(1)\n",
    "        sample, label = read_dataset_to_X_and_y(\n",
    "            file, range_feature, range_label, normalization, shuffle=shuffle,\n",
    "            about_nan=about_nan)\n",
    "        self.number_of_feature = sample.shape[1]\n",
    "        self.size_of_universal = sample.shape[0]\n",
    "        self.universal = sample.astype(float)\n",
    "        self.label = label\n",
    "        self.diffrent_label = np.unique(label)\n",
    "        self.number_of_diffrent_label = self.diffrent_label.shape[0]\n",
    "        self.relation = None\n",
    "        self.equivalence_relation = None\n",
    "\n",
    "\n",
    "uni_total = UniSet(\n",
    "    'dataset/hcvdat0.csv', (2, 14), (1, 2),\n",
    "    normalization='z_score', shuffle=True, about_nan='class_mean')\n",
    "\n",
    "\n",
    "print(f'The whole dataset is {uni_total.universal.shape} matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset is (492, 12) matrix\n",
      "The test dataset is (123, 12) matrix\n"
     ]
    }
   ],
   "source": [
    "def split_train_test(universe: UniSet, train_size: float) -> list[UniSet]:\n",
    "    train = deepcopy(universe)\n",
    "    test = deepcopy(universe)\n",
    "    train.size_of_universal = \\\n",
    "        int(universe.size_of_universal*train_size)\n",
    "    train.universal = \\\n",
    "        universe.universal[0:train.size_of_universal]\n",
    "    train.label = \\\n",
    "        universe.label[0:train.size_of_universal]\n",
    "    test.size_of_universal = (\n",
    "        universe.size_of_universal - train.size_of_universal)\n",
    "    test.universal = \\\n",
    "        universe.universal[train.size_of_universal:]\n",
    "    test.label = \\\n",
    "        universe.label[train.size_of_universal:]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "uni_train, uni_test = split_train_test(uni_total, 0.8)\n",
    "print(f'The train dataset is {uni_train.universal.shape} matrix')\n",
    "print(f'The test dataset is {uni_test.universal.shape} matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relation on train dataset is (492, 492) matrix\n",
      "The relation on test dataset is (123, 123) matrix\n"
     ]
    }
   ],
   "source": [
    "def distance(sample1: np.ndarray, sample2: np.ndarray) -> float:\n",
    "    return np.linalg.norm(sample1-sample2)\n",
    "\n",
    "\n",
    "def find_relation(universal: UniSet) -> np.ndarray:\n",
    "    dis = np.array(\n",
    "        list(map(lambda x: list(map(\n",
    "            lambda y: distance(\n",
    "                universal.universal[x], universal.universal[y]),\n",
    "            range(universal.size_of_universal))),\n",
    "            range(universal.size_of_universal))))\n",
    "    return 1 - dis / np.max(dis)\n",
    "\n",
    "\n",
    "uni_train.relation = find_relation(uni_train)\n",
    "print(f'The relation on train dataset is {uni_train.relation.shape} matrix')\n",
    "\n",
    "\n",
    "uni_test.relation = find_relation(uni_test)\n",
    "print(f'The relation on test dataset is {uni_test.relation.shape} matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration to make train relation transitive\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "The equivalence relation on train dataset is (492, 492) matrix\n",
      "\n",
      "#Iteration to make test relation transitive\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "The equivalence relation on test dataset is (123, 123) matrix\n"
     ]
    }
   ],
   "source": [
    "def max_min(sample1: np.ndarray, sample2: np.ndarray) -> float:\n",
    "    both_sample = np.vstack((sample1, sample2))\n",
    "    return np.max(np.min(both_sample, axis=0))\n",
    "\n",
    "\n",
    "def composition_RoR(relation: np.ndarray) -> np.ndarray:\n",
    "    result = np.array(\n",
    "        list(map(lambda x: list(map(\n",
    "            lambda y: max_min(relation[x], relation[y]),\n",
    "            range(relation.shape[0]))),\n",
    "            range(relation.shape[0]))))\n",
    "    return result\n",
    "\n",
    "\n",
    "def union_two_relation(\n",
    "        relation1: np.ndarray, relation2: np.ndarray) -> np.ndarray:\n",
    "    both_relation = np.dstack((relation1, relation2))\n",
    "    return np.max(both_relation, axis=2)\n",
    "\n",
    "\n",
    "def make_transitive(relation: np.ndarray) -> np.ndarray:\n",
    "    R = None\n",
    "    Rp = np.copy(relation)\n",
    "    iter = 0\n",
    "    while((Rp != R).any()):\n",
    "        R = np.copy(Rp)\n",
    "        RoR = composition_RoR(R)\n",
    "        Rp = union_two_relation(R, RoR)\n",
    "        iter += 1\n",
    "        print(iter)\n",
    "    return Rp\n",
    "\n",
    "\n",
    "print('#Iteration to make train relation transitive')\n",
    "uni_train.equivalence_relation = make_transitive(uni_train.relation)\n",
    "print('The equivalence relation on train dataset is',\n",
    "        f'{uni_train.equivalence_relation.shape} matrix')\n",
    "\n",
    "print('\\n#Iteration to make test relation transitive')\n",
    "uni_test.equivalence_relation = make_transitive(uni_test.relation)\n",
    "print('The equivalence relation on test dataset is',\n",
    "        f'{uni_test.equivalence_relation.shape} matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is our train equivalence relation, equivalence? True\n",
      "Is our test equivalence relation, equivalence? True\n"
     ]
    }
   ],
   "source": [
    "def is_reflexive(relation: np.ndarray) -> bool:\n",
    "    return (relation.diagonal() != 0).all()\n",
    "\n",
    "\n",
    "def is_symmetric(relation: np.ndarray) -> bool:\n",
    "    return (relation == relation.T).all()\n",
    "\n",
    "\n",
    "def is_transitive(relation: np.ndarray) -> bool:\n",
    "    RoR = composition_RoR(relation)\n",
    "    Rp = union_two_relation(relation, RoR)\n",
    "    return (Rp == relation).all()\n",
    "\n",
    "\n",
    "def is_equivalece(relation: np.ndarray) -> bool:\n",
    "    return is_reflexive(relation) & is_symmetric(relation) & \\\n",
    "        is_transitive(relation)\n",
    "\n",
    "\n",
    "print('Is our train equivalence relation, equivalence?',\n",
    "    f'{is_equivalece(uni_train.equivalence_relation)}')\n",
    "\n",
    "print('Is our test equivalence relation, equivalence?',\n",
    "    f'{is_equivalece(uni_test.equivalence_relation)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster with alpha-cut 0.93 on train equivalence relation is\n",
      "([array([  0,   1,   3,   6,   8,  12,  13,  14,  15,  16,  17,  20,  22,\n",
      "        31,  41,  44,  45,  46,  47,  49,  52,  57,  58,  59,  60,  66,\n",
      "        67,  76,  78,  79,  80,  82,  85,  89,  98, 101, 105, 107, 112,\n",
      "       128, 142, 144, 146, 153, 154, 161, 164, 168, 171, 172, 173, 175,\n",
      "       176, 178, 180, 185, 186, 190, 195, 197, 200, 203, 210, 214, 222,\n",
      "       223, 224, 226, 227, 228, 229, 231, 232, 234, 236, 238, 242, 243,\n",
      "       244, 245, 250, 253, 255, 258, 263, 264, 265, 266, 267, 272, 275,\n",
      "       276, 279, 284, 285, 288, 290, 291, 293, 295, 297, 299, 302, 305,\n",
      "       312, 313, 314, 316, 317, 322, 324, 326, 327, 328, 330, 332, 333,\n",
      "       337, 340, 347, 349, 355, 359, 360, 361, 364, 367, 370, 371, 376,\n",
      "       381, 382, 383, 388, 395, 398, 413, 423, 427, 437, 439, 441, 442,\n",
      "       444, 445, 446, 448, 450, 452, 462, 463, 466, 469, 470, 480, 481,\n",
      "       489, 490]), array([  2,   4,   7,   9,  10,  11,  18,  19,  23,  25,  28,  29,  30,\n",
      "        32,  33,  34,  35,  39,  40,  43,  48,  50,  51,  53,  55,  56,\n",
      "        62,  63,  64,  65,  68,  73,  74,  75,  77,  81,  83,  84,  86,\n",
      "        87,  88,  90,  92,  93,  95,  99, 102, 104, 108, 109, 110, 113,\n",
      "       114, 115, 116, 118, 119, 120, 123, 124, 126, 127, 129, 130, 131,\n",
      "       132, 134, 135, 136, 138, 139, 140, 141, 143, 149, 150, 151, 155,\n",
      "       156, 157, 159, 162, 166, 167, 169, 170, 174, 177, 179, 181, 182,\n",
      "       187, 188, 189, 191, 193, 194, 198, 199, 201, 202, 204, 205, 206,\n",
      "       207, 211, 212, 213, 215, 216, 217, 220, 221, 225, 233, 235, 237,\n",
      "       240, 246, 248, 251, 252, 256, 257, 259, 260, 261, 262, 268, 269,\n",
      "       270, 271, 273, 274, 277, 278, 280, 281, 282, 283, 286, 287, 289,\n",
      "       292, 296, 298, 301, 303, 304, 308, 309, 310, 311, 315, 321, 325,\n",
      "       329, 331, 334, 335, 336, 338, 339, 342, 343, 344, 345, 346, 348,\n",
      "       350, 351, 352, 353, 356, 357, 358, 362, 363, 365, 366, 368, 369,\n",
      "       372, 374, 377, 378, 379, 384, 385, 387, 389, 391, 392, 393, 401,\n",
      "       402, 403, 405, 406, 407, 409, 411, 414, 415, 416, 418, 419, 420,\n",
      "       421, 422, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434, 436,\n",
      "       438, 440, 447, 451, 453, 455, 456, 458, 459, 464, 465, 467, 468,\n",
      "       471, 473, 474, 475, 476, 484, 485, 491]), array([  5, 443]), array([21]), array([24, 36]), array([26]), array([27]), array([37]), array([38]), array([42]), array([54]), array([61]), array([69]), array([70]), array([71]), array([72]), array([91]), array([94]), array([96]), array([97]), array([100]), array([103]), array([106]), array([111]), array([117]), array([121]), array([122]), array([125]), array([133]), array([137]), array([145]), array([147]), array([148]), array([152]), array([158]), array([160]), array([163]), array([165]), array([183]), array([184]), array([192]), array([196]), array([208]), array([209]), array([218]), array([219]), array([230]), array([239]), array([241]), array([247]), array([249]), array([254]), array([294]), array([300]), array([306]), array([307, 318]), array([319]), array([320]), array([323]), array([341]), array([354]), array([373, 488]), array([375]), array([380]), array([386]), array([390]), array([394]), array([396]), array([397]), array([399]), array([400]), array([404]), array([408]), array([410]), array([412]), array([417]), array([435]), array([449]), array([454]), array([457]), array([460]), array([461]), array([472]), array([477]), array([478]), array([479]), array([482]), array([483]), array([486]), array([487])], 90)\n"
     ]
    }
   ],
   "source": [
    "def find_similarity_class(\n",
    "        universal: UniSet, target_sample: int, alpha: float) -> np.ndarray:\n",
    "    size_of_universal = universal.shape[0]\n",
    "    similarity_class = []\n",
    "    for sample in range(size_of_universal):\n",
    "        if(universal[sample, target_sample] >= alpha):\n",
    "            similarity_class.append(sample)\n",
    "    return np.array(similarity_class)\n",
    "\n",
    "\n",
    "def find_cluster(relation: np.ndarray, alpha: float, label=False):\n",
    "    size_of_universal = relation.shape[0]\n",
    "    classes = []\n",
    "    predicted_label = np.full((size_of_universal, 1), -1.0)\n",
    "    number_of_class = 0.0\n",
    "    for sample in range(size_of_universal):\n",
    "        if(predicted_label[sample] == -1):\n",
    "            new_class = find_similarity_class(relation, sample, alpha)\n",
    "            predicted_label[new_class] = number_of_class\n",
    "            number_of_class += 1\n",
    "            classes.append(new_class)\n",
    "    number_of_class = int(number_of_class)\n",
    "    if(label is True):\n",
    "        return predicted_label, number_of_class\n",
    "    return classes, number_of_class\n",
    "\n",
    "\n",
    "cluster_alpha_cut_93 = find_cluster(uni_train.equivalence_relation, 0.93)\n",
    "print('\\nCluster with alpha-cut 0.93 on train equivalence relation is')\n",
    "print(cluster_alpha_cut_93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha-cut is 0.8845327547116397 on train-dataset  with f1-score 0.9296903460837888\n"
     ]
    }
   ],
   "source": [
    "def evaluate(gold_label: np.ndarray, predict_label: np.ndarray,\n",
    "             method: str = 'f1-score') -> float:\n",
    "    diffrent_label_in_gold_label = np.unique(gold_label)\n",
    "    diffrent_label_in_predict_label = np.unique(predict_label)\n",
    "    conf_mat = np.array(\n",
    "        list(map(lambda k: list(map(\n",
    "            lambda s: sum((predict_label == k)*(gold_label == s))[0],\n",
    "            diffrent_label_in_gold_label)),\n",
    "            diffrent_label_in_predict_label)))\n",
    "    precision = np.sum(np.max(conf_mat, axis=1)) / np.sum(conf_mat)\n",
    "    recall = np.sum(np.max(conf_mat, axis=0)) / np.sum(conf_mat)\n",
    "    if(method == 'precision'):\n",
    "        return precision\n",
    "    if(method == 'recall'):\n",
    "        return recall\n",
    "    if(method == 'f1-score'):\n",
    "        return 2 * ((precision*recall)/(precision+recall))\n",
    "\n",
    "\n",
    "def find_best_alpha_cut(universal: UniSet, plotter: bool = False) -> float:\n",
    "    alpha_cut = []\n",
    "    accuracy = []\n",
    "    last_point = -1.0\n",
    "    for alpha in np.unique(universal.equivalence_relation):\n",
    "        if(alpha - last_point >= 0.001):\n",
    "            alpha_cut.append(alpha)\n",
    "            accuracy.append(evaluate(\n",
    "                universal.label,\n",
    "                find_cluster(universal.equivalence_relation, alpha, True)[0]))\n",
    "            last_point = alpha\n",
    "    \n",
    "    if(plotter is True):\n",
    "        plt.plot(alpha_cut, accuracy)\n",
    "        plt.show()\n",
    "    \n",
    "    return alpha_cut[np.argmax(accuracy)], np.max(accuracy)\n",
    "\n",
    "\n",
    "best_alpha_cut, best_alpha_cut_accuracy = find_best_alpha_cut(uni_train)\n",
    "print(f'Best alpha-cut is {best_alpha_cut} on train-dataset',\n",
    "        f' with f1-score {best_alpha_cut_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our f1-score on test-dataset with best alpha-cut on train-set is 0.9396551724137931\n"
     ]
    }
   ],
   "source": [
    "predicted_label_test = find_cluster(\n",
    "    uni_test.equivalence_relation, best_alpha_cut, True)[1]\n",
    "test_accuracy = evaluate(uni_test.label, predicted_label_test)\n",
    "print('Our f1-score on test-dataset with best alpha-cut on train-set is',\n",
    "        test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print('Hi')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
